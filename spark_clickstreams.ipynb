{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "spark-clickstreams.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGAybWjfqk4m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "cellView": "form",
        "outputId": "40b2944b-8dba-45c5-9406-f16e0196880d"
      },
      "source": [
        "#@title Downloads\n",
        "%%bash\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00000.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00001.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00002.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00003.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00004.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00005.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00006.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00007.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00008.json.gz\"\n",
        "wget \"https://d3l36jjwr70u5l.cloudfront.net/data-engineer-test/part-00009.json.gz\"\n",
        "mkdir data-engineer-test\n",
        "mv part-*.gz data-engineer-test/\n",
        "wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "unzip ngrok-stable-linux-amd64.zip -o .\n",
        "pip install pyspark"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 0 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8p9v4X9abma1",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Truncamento dos dados\n",
        "# se estiver testando no jupyter notebook, rode esse script para truncar os dados\n",
        "\n",
        "import os\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "a = os.listdir(\"data-engineer-test/\")\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local\") \\\n",
        "    .appName(\"EscaleTT\") \\\n",
        "    .config(\"spark.driver.memory\", \"12g\") \\\n",
        "    .config(\"spark.executor.memory\", \"12g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "for i in a:\n",
        "    spark.read.schema(schema).json(\"data-engineer-test/\"+i).limit(10000).write.json(\"data-engineer-test-trunc/\"+i)\n",
        "\n",
        "!ls data-engineer-test-trunc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Lc5lZt7KdPc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "cellView": "form",
        "outputId": "c1d6c5e3-2b81-461d-c446-7718abe3e495"
      },
      "source": [
        "#@title Monitoramento de jobs \n",
        "# tunelamento http para ver a spark-ui\n",
        "# rode o código abaixo e use o link https://*.ngrok.io no arquivo de log para acessar o monitoramento\n",
        "%%bash --bg\n",
        "./ngrok http 4040 -log ngrok-outfile &\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 10 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbM_Z9AsQzxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cat ngrok-outfile"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46VdsDditwdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as f\n",
        "from pyspark.sql.types import (\n",
        "    LongType,\n",
        "    FloatType,\n",
        "    StringType,\n",
        "    StructType,\n",
        "    StructField,\n",
        "    IntegerType\n",
        ")\n",
        "\n",
        "spark = SparkSession \\\n",
        "    .builder \\\n",
        "    .master(\"local\") \\\n",
        "    .appName(\"EscaleTT\") \\\n",
        "    .config(\"spark.driver.memory\", \"12g\") \\\n",
        "    .config(\"spark.executor.memory\", \"12g\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# dados truncados para teste no jupyter notebook, use o .py para rodar um job no cluster\n",
        "datapath = \"file:///content/data-engineer-test-trunc/part-00*.json.gz\"\n",
        "schema = StructType([\n",
        "            StructField(\"n\", IntegerType(), True),\n",
        "            StructField(\"event\", StringType(), True),\n",
        "            StructField(\"version\", FloatType(), True),\n",
        "            StructField(\"platform\", StringType(), True),\n",
        "            StructField(\"os_family\", StringType(), True),\n",
        "            StructField(\"anonymous_id\", StringType(), True),\n",
        "            StructField(\"device_family\", StringType(), True),\n",
        "            StructField(\"browser_family\", StringType(), True),\n",
        "            StructField(\"device_sent_timestamp\", StringType(), True)\n",
        "    ]\n",
        ")\n",
        "\n",
        "df = spark \\\n",
        "    .read \\\n",
        "    .schema(schema) \\\n",
        "    .json(datapath) \\\n",
        "    .withColumn(\"file\",f.input_file_name()) \\\n",
        "    .withColumn(\"device_sent_timestamp\", f.substring(f.col(\"device_sent_timestamp\"),0,10)) \\\n",
        "    .withColumn(\"device_sent_timestamp\", f.from_unixtime(f.col(\"device_sent_timestamp\")))\n",
        "\n",
        "\n",
        "# FAZENDO SESSIONAMENTO\n",
        "# IMPORTANTE: arredondei o tempo máximo de sessão pra 1 hora, ao invés de 30 minutos\n",
        "df = df.withColumn(\"session_timestamp\", f.date_trunc(\"hour\",\"device_sent_timestamp\")) \n",
        "\n",
        "session_cols = [\n",
        "    # f.col(\"anonymous_id\"), # IMPORTANTE:  anonymous_id gerava um hash único pra cada linha, decidi dropar\n",
        "    # fingerprinting está sendo feito por User-Agent e timestamp\n",
        "    f.col(\"os_family\"),\n",
        "    f.col(\"device_family\"),\n",
        "    f.col(\"browser_family\"),\n",
        "    f.col(\"session_timestamp\") \n",
        "]\n",
        "df = df.withColumn(\"session_id\", f.sha2(f.concat(*session_cols),256))\n",
        "\n",
        "# ETAPA 1\n",
        "stage1 = df \\\n",
        ".groupBy(f.col(\"file\")) \\\n",
        ".agg(f.countDistinct(f.col(\"session_id\")).alias(\"unique_sessions\")) \\\n",
        ".rdd.collectAsMap()\n",
        "\n",
        "# ETAPA 2\n",
        "def unique_sessions(family):\n",
        "    return df \\\n",
        "    .groupBy(f.col(family)) \\\n",
        "    .agg(f.countDistinct(f.col(\"session_id\")).alias(\"unique_sessions\")) \\\n",
        "    .rdd.collectAsMap()\n",
        "\n",
        "stage2 = {\n",
        "    \"os_family\": unique_sessions(\"os_family\"),\n",
        "    \"device_family\": unique_sessions(\"device_family\"),\n",
        "    \"browser_family\": unique_sessions(\"browser_family\")\n",
        "} \n",
        "\n",
        "# ETAPA 3\n",
        "session_duration = f.unix_timestamp(f.col(\"session_end\")) - f.unix_timestamp(f.col(\"session_start\"))\n",
        "session_start_and_end = ( f.min(\"device_sent_timestamp\").alias(\"session_start\"), f.max(\"device_sent_timestamp\").alias(\"session_end\") )\n",
        "\n",
        "df2 = df.groupBy(f.col(\"session_id\")) \\\n",
        "    .agg(*session_start_and_end) \\\n",
        "    .withColumn(\"session_duration\", session_duration)\n",
        "\n",
        "df = df.join(df2,\"session_id\")\n",
        "\n",
        "def median_session_duration(family):\n",
        "    return df \\\n",
        "    .groupBy(f.col(\"os_family\")) \\\n",
        "    .agg(f.expr('percentile_approx(session_duration, 0.5)').alias(\"median_duration\")) \\\n",
        "    .rdd.collectAsMap()\n",
        "\n",
        "stage3 = {\n",
        "    \"os_family\": median_session_duration(\"os_family\"),\n",
        "    \"browser_family\": median_session_duration(\"browser_family\"),\n",
        "    \"device_family\": median_session_duration(\"device_family\")\n",
        "}\n",
        "\n",
        "stage1,stage2,stage3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOH-z9_B87fk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import json\n",
        "import errno\n",
        "\n",
        "\n",
        "def safe_write_json(dict_,path):\n",
        "    if not os.path.exists(os.path.dirname(path)):\n",
        "        try:\n",
        "            os.makedirs(os.path.dirname(path))\n",
        "        except OSError as exc:\n",
        "            if exc.errno != errno.EEXIST:\n",
        "                raise exc\n",
        "    with open(path,\"w\") as f:\n",
        "        json.dump(dict_,f)\n",
        "\n",
        "\n",
        "safe_write_json(stage1,\"sessions/unique/by_file.json\")\n",
        "safe_write_json(stage1,\"sessions/unique/by_family.json\")\n",
        "safe_write_json(stage1,\"sessions/median/by_family.json\")"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr4eOJNce-E_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "cellView": "form",
        "outputId": "35ac4c8a-06ba-4d07-ebcf-a2e6a1d29540"
      },
      "source": [
        "#@title REST API\n",
        "%%writefile main.py\n",
        "\n",
        "from typing import Optional, List\n",
        "from fastapi import FastAPI, Query\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "\n",
        "@app.get(\"/\")\n",
        "def read_root():\n",
        "    return {}\n",
        "\n",
        "\n",
        "# /sessions/unique?by=family\n",
        "@app.get(\"/sessions/{metric}/\")\n",
        "def read_metric(metric:str, q: str = Query(default=\"file\",alias=\"by\")):\n",
        "    metric = metric.strip().lower()\n",
        "    if q not in [\"file\",\"family\"]: return {}\n",
        "    if metric not in [\"median\",\"unique\"]: return {}\n",
        "\n",
        "    return json.load(f\"sessions/{median}/by_{q}.json\")\n",
        "\n",
        "\n",
        "# {\n",
        "#     \"metric\": \"median\",\n",
        "#     \"by\": \"file\"\n",
        "# }\n",
        "# @app.post(\"/jobs/\")\n",
        "# def read_metric(payload:dict):\n",
        "#     pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting main.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jRu-WpGKanc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "e1c57e79-6241-49de-e873-c5c820e4571e"
      },
      "source": [
        "%%bash --bg\n",
        "pip install fastapi uvicorn\n",
        "uvicorn main:app --reload &&"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting job # 7 in a separate thread.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5SUkzIgRsID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash --bg\n",
        "# to use the API\n",
        "./ngrok http 8000 -log ngrok-outfile"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}